{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d52f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ObjectToObjectRecommender import ObjectToObjectRecommender as OTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ce73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tk().withdraw()\n",
    "\n",
    "# def getPatronPath():\n",
    "#     filename = askopenfilename()\n",
    "#     return(filename)\n",
    "\n",
    "# def getInventoryPath():\n",
    "#     filename = askopenfilename()\n",
    "#     return(filename)\n",
    "\n",
    "# Remove to select folder or paste path below.\n",
    "# patron_path = getPatronPath()\n",
    "# inventory_pat = getInventoryPath()\n",
    "\n",
    "patron_path = 'C:/Users/Ben/Desktop/HRP/Data/Clean_Data/Clean_Patron.csv'\n",
    "inventory_path = 'C:/Users/Ben/Desktop/HRP/Data/Clean_Data/Clean_Inventory.csv'\n",
    "\n",
    "patron_df = pd.read_csv(patron_path)\n",
    "inv_df = pd.read_csv(inventory_path)\n",
    "\n",
    "# Drop random columns\n",
    "patron_df.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "inv_df.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5157b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Instances of an item to item and user to user comparators\n",
    "iti = OTO(patron_df, 'Patron_ID', 'Item_ID')\n",
    "ptp = OTO(patron_df, 'Item_ID', 'Patron_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e62b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patron_pairs(patron_id):\n",
    "    '''\n",
    "    Creates a list of positive patron and item pairs and an equally as large list of negative pairs\n",
    "    '''\n",
    "    pair_list = []\n",
    "\n",
    "    # Get a list of pairs of patron, item that the patron has read.\n",
    "    has_list = iti.objects_by_actor[patron_id]\n",
    "    for item in has_list:\n",
    "        pair_list.append([patron_id, item, 1])\n",
    "\n",
    "    has_len = len(pair_list)\n",
    "\n",
    "    # Get a list of pairs of patron, item that the patron hasn't read.\n",
    "    hasnt_list = random.sample([x for x in iti.object_ids if x not in has_list], has_len)\n",
    "\n",
    "    for item in hasnt_list:\n",
    "        pair_list.append([patron_id, item, 0])\n",
    "\n",
    "    return pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ad2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_vec(pair):\n",
    "    '''\n",
    "    Creates a list of selected features for any patron and item pair.\n",
    "    '''\n",
    "    feat_vec = []\n",
    "\n",
    "    # User-Item pair (u, i)\n",
    "    patron = pair[0]\n",
    "    item = pair[1]\n",
    "\n",
    "    # Popularity of i\n",
    "    feat_vec.append(len(patron_df[patron_df['Item_ID'] == item]))\n",
    "\n",
    "    # The similarity between i and the most similar book the user u has read\n",
    "    max = 0\n",
    "    items_read = iti.get_objects(patron)\n",
    "\n",
    "    for item_id in items_read:\n",
    "        sim_score = iti.jaccard(item, item_id)\n",
    "        if sim_score > max:\n",
    "            max = sim_score\n",
    "\n",
    "    feat_vec.append(max)\n",
    "\n",
    "    # The similarity between the user u and the most similar user who has read i\n",
    "    max = 0\n",
    "    patron_read = ptp.get_objects(item)\n",
    "\n",
    "    for patron_id in patron_read:\n",
    "        sim_score = ptp.jaccard(patron, patron_id)\n",
    "        if sim_score > max:\n",
    "            max = sim_score\n",
    "\n",
    "    feat_vec.append(max)\n",
    "\n",
    "    return feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfd5c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user and item pairs for all users in the test DataFrame\n",
    "pairs_lists = [get_patron_pairs(patron_id) for patron_id in set(iti.actor_ids)]\n",
    "\n",
    "# unpack user and item pair list into the pair list and label list\n",
    "pairs  = []\n",
    "label_list = []\n",
    "\n",
    "for pair_list in pairs_lists:\n",
    "    for pair in pair_list:\n",
    "        pairs.append(pair[:2])\n",
    "        label_list.append(pair[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "680a78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the feature vector for each pair\n",
    "pair_feats = [get_feat_vec(pair) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b1699d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the feature vectors and labels into 75% for training an 25% for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(pair_feats, label_list, test_size=0.25, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8c410d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initailize the model and fit to the training data.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23fecb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "accuracy =  1 - (y_test - y_pred).sum() / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ce83424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53d26375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "# cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# target_names = ['shouldn\\'t checkout', 'should checkout']\n",
    "# print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a3fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
